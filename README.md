# 神经网络和深度学习课程作业——构建两层神经网络分类器

## 姓名：罗健洲，学号：21210980054

## 1 数据来源
MNIST是一个手写体数字的图片数据集，该数据集来由美国国家标准与技术研究所（National Institute of Standards and Technology (NIST)）发起整理，一共统计了来自250个不同的人手写数字图片。该数据集常用于对分类算法的效果测试，包含60000个训练集样本和10000个测试集样本。

## 2 代码介绍
### mnist.py
*用于数据的读取。将训练集或测试集样本中的每张图片读取为由784个元素组成的列向量并堆叠起来，同时生成一个由0和1构成的矩阵表示各图对应的label。*

### model.py
*用于模型的建立。本项目构建两层神经网络，隐藏层中选择ReLU作为激活函数，输出层则选择softmax函数作为激活函数。损失函数选择交叉熵函数，并为模型添加了L2正则项。对参数进行随机初始化后。通过前向传播计算每一次迭代各层的计算结果，通过反向传播计算每一次迭代各参数对应的梯度。然后，构建出每一步迭代的SGD优化过程(添加动量超参数）。*

### TrainTest.py
*用于数据的训练。构建迭代器生成每一个batch中的数据，输入模型更新参数。每经过固定数量的epoch以后，步长（即学习率）指数性下降一次。同时，记录每次epoch的parameter path。通过参考在测试集中模型的分类精度确定最优的参数进行参数查找。将最优的模型参数保存。*

### draw.py
*用于实验结果的展示*

### NN.py
*使用最优的参数构建一个完整的模型*

### NN_example.py
*尝试使用该模型*


## 3 实验结果
本项目在经过多次实验进行最优参数选择之后，确定了神经网络各层各项参数（隐层维数为300），得到最终的测试准确率为**95.2%**，并将各epoch的训练集loss函数值、测试集loss函数值，和测试的准确率进行可视化，同时也对每个epoch两层网络的参数的F范数进行了可视化。细节见提交的pdf文件。
最后，将各项参数保存在.json格式的文件中，可随时调用。

模型及参数百度网盘链接：
链接: https://pan.baidu.com/s/1CAdJrcZdzsehOjCRSKjeaA 提取码: 2val 
